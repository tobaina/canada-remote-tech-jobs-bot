name: Post Canada Remote Tech Jobs

on:
  workflow_dispatch:
  schedule:
    # Runs daily at 09:00 UTC
    - cron: "0 9 * * *"

jobs:
  post_jobs:
    runs-on: ubuntu-latest

    steps:
      - name: Fetch Greenhouse jobs + post to Slack
        env:
          SLACK_BOT_TOKEN: ${{ secrets.SLACK_BOT_TOKEN }}
          SLACK_CHANNEL: ${{ secrets.SLACK_CHANNEL }}

          # âœ… EDIT THIS LIST (these are Greenhouse "board tokens")
          # Example: if a company's Greenhouse URL is:
          # https://boards.greenhouse.io/shopify  -> token is "shopify"
          GREENHOUSE_BOARDS: "shopify github notion datadog"

          # Filters: adjust if you want
          # Matches: Remote + Canada keywords in location
          LOCATION_REGEX: "(?i)(remote|canada|toronto|vancouver|montreal|calgary|ottawa)"

          # How many jobs to post per run (max)
          MAX_POSTS: "12"

        run: |
          set -euo pipefail

          echo "Boards: $GREENHOUSE_BOARDS"
          echo "Location regex: $LOCATION_REGEX"
          echo "Max posts: $MAX_POSTS"

          # Temp files
          OUT_TSV="$(mktemp)"
          OUT_UNIQ="$(mktemp)"

          # Collect jobs from all boards
          for BOARD in $GREENHOUSE_BOARDS; do
            echo "Fetching: $BOARD"
            URL="https://boards-api.greenhouse.io/v1/boards/${BOARD}/jobs?content=true"

            JSON="$(mktemp)"
            curl -sS -H "Accept: application/json" "$URL" -o "$JSON"

            # Validate JSON (skip board safely if invalid)
            if ! jq -e . "$JSON" >/dev/null 2>&1; then
              echo "âŒ Invalid JSON from board: $BOARD (skipping)"
              continue
            fi

            # Extract jobs as TSV: company(board) | title | location | url
            # Filter by location regex to focus Canada/Remote
            jq -r --arg company "$BOARD" --arg re "$LOCATION_REGEX" '
              .jobs[]
              | select((.location.name // "" ) | test($re))
              | [
                  $company,
                  (.title // ""),
                  (.location.name // ""),
                  (.absolute_url // "")
                ]
              | @tsv
            ' "$JSON" >> "$OUT_TSV" || true
          done

          # Deduplicate by URL, keep first occurrence
          awk -F'\t' '!seen[$4]++' "$OUT_TSV" > "$OUT_UNIQ"

          COUNT=$(wc -l < "$OUT_UNIQ" | tr -d ' ')
          echo "Found $COUNT matching jobs total."

          if [ "$COUNT" -eq 0 ]; then
            echo "No jobs matched filters. Exiting without posting."
            exit 0
          fi

          # Limit posts
          head -n "$MAX_POSTS" "$OUT_UNIQ" > "${OUT_UNIQ}.top"

          # Build Slack message (single post)
          TEXT="*ðŸ‡¨ðŸ‡¦ Remote / Canada Tech Jobs (Greenhouse)*\n"
          while IFS=$'\t' read -r COMPANY TITLE LOCATION LINK; do
            # Slack-friendly line
            TEXT="${TEXT}â€¢ *${TITLE}* â€” ${COMPANY} (${LOCATION})\n${LINK}\n"
          done < "${OUT_UNIQ}.top"

          echo "Posting to Slack channel: $SLACK_CHANNEL"

          # Post to Slack
          curl -sS -X POST "https://slack.com/api/chat.postMessage" \
            -H "Authorization: Bearer $SLACK_BOT_TOKEN" \
            -H "Content-Type: application/json; charset=utf-8" \
            --data "$(jq -n --arg channel "$SLACK_CHANNEL" --arg text "$TEXT" \
              '{channel:$channel, text:$text}')" \
            | jq -r '.ok as $ok | if $ok then "âœ… Posted successfully" else "âŒ Slack error: " + (.error // "unknown") end'
